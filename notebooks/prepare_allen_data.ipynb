{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/yzhang39/miniconda3/envs/decoding/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load data, processes it, save it.\"\"\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/scratch/bdtg/yzhang39/allen/datasets\" \n",
    "input_dir = f\"{data_dir}/raw\"\n",
    "output_dir = f\"{data_dir}/processed\"\n",
    "\n",
    "# get the project cache from the warehouse\n",
    "manifest_path = os.path.join(input_dir, \"manifest.json\")\n",
    "cache = EcephysProjectCache.from_warehouse(manifest=manifest_path)\n",
    "# get sessions\n",
    "sessions = cache.get_session_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "/u/yzhang39/miniconda3/envs/decoding/lib/python3.11/site-packages/hdmf/spec/namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/u/yzhang39/miniconda3/envs/decoding/lib/python3.11/site-packages/hdmf/spec/namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "INFO:root:Processing session: 715093703\n",
      "0it [00:14, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for session_id, row in tqdm(sessions.iterrows()):\n",
    "    # load nwb file through the allen sdk\n",
    "    session_data = cache.get_session_data(session_id)\n",
    "    stimulus_presentations = session_data.stimulus_presentations\n",
    "\n",
    "    logging.info(f\"Processing session: {session_id}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spikes(session, session_id):\n",
    "\n",
    "    units = session.units\n",
    "    spiketimes_dict = session.spike_times\n",
    "\n",
    "    spikes = []\n",
    "    unit_index = []\n",
    "    unit_meta = []\n",
    "\n",
    "    for i, unit_id in enumerate(spiketimes_dict.keys()):\n",
    "        metadata = units.loc[unit_id]\n",
    "        probe_id = metadata[\"probe_id\"]\n",
    "        probe_channel_id = metadata[\"probe_channel_number\"]\n",
    "        unit_name = f\"{session_id}/{probe_id}/{probe_channel_id}/{unit_id}\"\n",
    "\n",
    "        spiketimes = spiketimes_dict[unit_id]\n",
    "        spikes.append(spiketimes)\n",
    "        unit_index.append([i] * len(spiketimes))\n",
    "\n",
    "        unit_meta.append(\n",
    "            {\n",
    "                \"count\": len(spiketimes),\n",
    "                \"channel_name\": probe_channel_id,\n",
    "                \"electrode_row\": metadata[\"probe_horizontal_position\"],\n",
    "                \"electrode_col\": 0,\n",
    "                \"id\": unit_name,\n",
    "                \"area_name\": metadata[\"structure_acronym\"],\n",
    "                \"channel_number\": probe_channel_id,\n",
    "                \"unit_number\": i,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    spikes = np.concatenate(spikes)\n",
    "    unit_index = np.concatenate(unit_index)\n",
    "\n",
    "    # convert unit metadata to a Data object\n",
    "    unit_meta_df = pd.DataFrame(unit_meta)\n",
    "    units = {\n",
    "        \"unit_index\": unit_index, \n",
    "        \"unit_meta_df\": unit_meta_df,\n",
    "    }\n",
    "\n",
    "    return spikes, units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_running_speed(session):\n",
    "\n",
    "    running_speed_dict = {}\n",
    "    running_speed_df = session.running_speed\n",
    "    if running_speed_df is not None:\n",
    "        running_speed_df = running_speed_df[~running_speed_df.isnull().any(axis=1)]\n",
    "        running_speed_times = (\n",
    "            running_speed_df[\"start_time\"]\n",
    "            + (running_speed_df[\"end_time\"] - running_speed_df[\"start_time\"]) / 2\n",
    "        )\n",
    "        running_speed_dict.update(\n",
    "            {\n",
    "                \"timestamps\": running_speed_times.values,\n",
    "                \"running_speed\": running_speed_df[\"velocity\"]\n",
    "                .values.astype(np.float32)\n",
    "                .reshape(-1, 1),  # continues values needs to be 2 dimensional\n",
    "            }\n",
    "        )\n",
    "    return running_speed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This ecephys session '715093703' has no eye tracking data. (NWB error: \"'raw_gaze_mapping' not found in processing of NWBFile 'root'.\")\n"
     ]
    }
   ],
   "source": [
    "def extract_gaze(session):\n",
    "    gaze_df = session.get_screen_gaze_data(include_filtered_data=True)\n",
    "\n",
    "    if gaze_df is None:\n",
    "        return None\n",
    "\n",
    "    # Filter out rows with nan values\n",
    "    gaze_df = gaze_df[~gaze_df.isnull().any(axis=1)]\n",
    "\n",
    "    gaze_dict = {\n",
    "        \"timestamps\": gaze_df.index.values,\n",
    "        \"raw_eye_area\": gaze_df[\"raw_eye_area\"].values.astype(np.float32),\n",
    "        \"raw_pupil_area\": gaze_df[\"raw_pupil_area\"].values.astype(np.float32),\n",
    "        \"raw_screen_coordinates_x_cm\": gaze_df[\n",
    "            \"raw_screen_coordinates_x_cm\"\n",
    "        ].values.astype(np.float32),\n",
    "        \"raw_screen_coordinates_y_cm\": gaze_df[\n",
    "            \"raw_screen_coordinates_y_cm\"\n",
    "        ].values.astype(np.float32),\n",
    "        \"raw_screen_coordinates_spherical_x_deg\": gaze_df[\n",
    "            \"raw_screen_coordinates_spherical_x_deg\"\n",
    "        ].values.astype(np.float32),\n",
    "        \"raw_screen_coordinates_spherical_y_deg\": gaze_df[\n",
    "            \"raw_screen_coordinates_spherical_y_deg\"\n",
    "        ].values.astype(np.float32),\n",
    "        \"filtered_eye_area\": gaze_df[\"filtered_eye_area\"].values.astype(np.float32),\n",
    "        \"filtered_pupil_area\": gaze_df[\"filtered_pupil_area\"].values.astype(np.float32),\n",
    "        \"filtered_screen_coordinates_x_cm\": gaze_df[\n",
    "            \"filtered_screen_coordinates_x_cm\"\n",
    "        ].values.astype(np.float32),\n",
    "        \"filtered_screen_coordinates_y_cm\": gaze_df[\n",
    "            \"filtered_screen_coordinates_y_cm\"\n",
    "        ].values.astype(np.float32),\n",
    "        \"filtered_screen_coordinates_spherical_x_deg\": gaze_df[\n",
    "            \"filtered_screen_coordinates_spherical_x_deg\"\n",
    "        ].values.astype(np.float32),\n",
    "        \"filtered_screen_coordinates_spherical_y_deg\": gaze_df[\n",
    "            \"filtered_screen_coordinates_spherical_y_deg\"\n",
    "        ].values.astype(np.float32),\n",
    "    }\n",
    "\n",
    "    gaze_dict[\"pos_2d\"] = np.stack(\n",
    "        [\n",
    "            gaze_dict[\"filtered_screen_coordinates_x_cm\"],\n",
    "            gaze_dict[\"filtered_screen_coordinates_y_cm\"],\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )  # (N, 2)\n",
    "\n",
    "    return gaze_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This ecephys session '715093703' has no eye tracking data. (NWB error: \"'eye_tracking' not found in processing of NWBFile 'root'.\")\n"
     ]
    }
   ],
   "source": [
    "def extract_pupil(session):\n",
    "    pupil_df = session.get_pupil_data()\n",
    "    if pupil_df is None:\n",
    "        return None\n",
    "\n",
    "    pupil_df = pupil_df[~pupil_df.isnull().any(axis=1)]\n",
    "    pupil_dict = {\n",
    "        \"timestamps\": pupil_df.index.values,\n",
    "        \"corneal_reflection_center_x\": pupil_df[\n",
    "            \"corneal_reflection_center_x\"\n",
    "        ].values.astype(np.float32),\n",
    "        \"corneal_reflection_center_y\": pupil_df[\n",
    "            \"corneal_reflection_center_y\"\n",
    "        ].values.astype(np.float32),\n",
    "        \"corneal_reflection_height\": pupil_df[\"corneal_reflection_height\"].values.astype(\n",
    "            np.float32\n",
    "        ),\n",
    "        \"corneal_reflection_width\": pupil_df[\"corneal_reflection_width\"].values.astype(\n",
    "            np.float32\n",
    "        ),\n",
    "        \"corneal_reflection_phi\": pupil_df[\"corneal_reflection_phi\"].values.astype(\n",
    "            np.float32\n",
    "        ),\n",
    "        \"pupil_center_x\": pupil_df[\"pupil_center_x\"].values.astype(np.float32),\n",
    "        \"pupil_center_y\": pupil_df[\"pupil_center_y\"].values.astype(np.float32),\n",
    "        \"pupil_height\": pupil_df[\"pupil_height\"].values.astype(np.float32),\n",
    "        \"pupil_width\": pupil_df[\"pupil_width\"].values.astype(np.float32),\n",
    "        \"pupil_phi\": pupil_df[\"pupil_phi\"].values.astype(np.float32),\n",
    "        \"eye_center_x\": pupil_df[\"eye_center_x\"].values.astype(np.float32),\n",
    "        \"eye_center_y\": pupil_df[\"eye_center_y\"].values.astype(np.float32),\n",
    "        \"eye_height\": pupil_df[\"eye_height\"].values.astype(np.float32),\n",
    "        \"eye_width\": pupil_df[\"eye_width\"].values.astype(np.float32),\n",
    "        \"eye_phi\": pupil_df[\"eye_phi\"].values.astype(np.float32),\n",
    "    }\n",
    "\n",
    "    pupil_dict[\"size_2d\"] = np.stack(\n",
    "        [pupil_dict.pupil_height, pupil_dict.pupil_width], axis=-1\n",
    "    )  # (N, 2)\n",
    "\n",
    "    return pupil_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_natural_scenes(stimulus_pres):\n",
    "    ns_presentations = stimulus_pres[\n",
    "        np.array(stimulus_pres[\"stimulus_name\"] == \"natural_scenes\")\n",
    "        & np.array(stimulus_pres[\"frame\"] != \"null\")\n",
    "    ]\n",
    "\n",
    "    if len(ns_presentations) == 0:\n",
    "        return None\n",
    "\n",
    "    start_times = ns_presentations[\"start_time\"].values\n",
    "    end_times = ns_presentations[\"stop_time\"].values\n",
    "    image_ids = ns_presentations[\"frame\"].values.astype(np.int64)  # ids span -1 to 117\n",
    "    image_ids = image_ids + 1  # now they span 0 to 118\n",
    "\n",
    "    return {\n",
    "        \"start\": start_times,\n",
    "        \"end\": end_times,\n",
    "        \"image_ids\": image_ids,\n",
    "        \"timestamps\": start_times / 2.0 + end_times / 2.0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gabors(stimulus_pres):\n",
    "    gabors_presentations = stimulus_pres[\n",
    "        np.array(stimulus_pres[\"stimulus_name\"] == \"gabors\")\n",
    "        & np.array(stimulus_pres[\"orientation\"] != \"null\")\n",
    "    ]\n",
    "\n",
    "    unique_x_pos = np.unique(gabors_presentations.x_position)\n",
    "    unique_y_pos = np.unique(gabors_presentations.y_position)\n",
    "    unique_orientations = np.unique(gabors_presentations.orientation)\n",
    "    unique_x_pos.sort()\n",
    "    unique_y_pos.sort()\n",
    "    unique_orientations.sort()\n",
    "\n",
    "    def calculate_gabors_ori(row):\n",
    "        gabors_or_map = {\"0\": 0, \"45\": 1, \"90\": 2}\n",
    "        return gabors_or_map[str(int(row[\"orientation\"]))]\n",
    "\n",
    "    def calculate_gabors_pos2d(row):\n",
    "        x_class = np.where(unique_x_pos == row[\"x_position\"])[0][0]\n",
    "        y_class = np.where(unique_y_pos == row[\"y_position\"])[0][0]\n",
    "        return np.array([x_class, y_class])\n",
    "\n",
    "    gabors_start_times = gabors_presentations[\"start_time\"].values\n",
    "    gabors_end_times = gabors_presentations[\"stop_time\"].values\n",
    "\n",
    "    gabors_trials = {\n",
    "        \"start\": gabors_start_times,\n",
    "        \"end\": gabors_end_times,\n",
    "        \"pos_2d\": np.vstack(\n",
    "            gabors_presentations.apply(calculate_gabors_pos2d, axis=1).to_numpy()\n",
    "        ),  # (N, 2)\n",
    "        \"gabors_orientation\": gabors_presentations.apply(\n",
    "            calculate_gabors_ori, axis=1\n",
    "        ).to_numpy(),\n",
    "        \"timestamps\": gabors_start_times / 2.0 + gabors_end_times / 2.0,\n",
    "        # other data that might be useful later\n",
    "        \"orientation\": gabors_presentations[\"orientation\"].values.astype(\n",
    "            np.float32\n",
    "        ),  # (N,)\n",
    "        \"spatial_frequency\": gabors_presentations[\"spatial_frequency\"].values.astype(\n",
    "            np.float32\n",
    "        ),\n",
    "        \"temporal_frequency\": gabors_presentations[\"temporal_frequency\"].values.astype(\n",
    "            np.float32\n",
    "        ),\n",
    "        \"x_position\": gabors_presentations[\"x_position\"].values.astype(np.float32),\n",
    "        \"y_position\": gabors_presentations[\"y_position\"].values.astype(np.float32),\n",
    "    }\n",
    "    return gabors_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_static_gratings(stimulus_pres):\n",
    "    static_gratings = stimulus_pres[\n",
    "        (stimulus_pres[\"stimulus_name\"] == \"static_gratings\")\n",
    "        & (stimulus_pres[\"orientation\"] != \"null\")\n",
    "    ]\n",
    "\n",
    "    start_times = static_gratings[\"start_time\"].values\n",
    "    end_times = static_gratings[\"stop_time\"].values\n",
    "    orientations = static_gratings[\"orientation\"].values.astype(np.float32)\n",
    "    orientation_classes = np.round(orientations / 30.0).astype(np.int64)\n",
    "    output_timestamps = (start_times + end_times) / 2\n",
    "\n",
    "    return {\n",
    "        \"start\": start_times,\n",
    "        \"end\": end_times,\n",
    "        \"orientation\": orientation_classes,  # (N,)\n",
    "        \"timestamps\": output_timestamps,  # (N,)\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_drifting_gratings(stimulus_pres):\n",
    "    drifting_gratings = stimulus_pres[\n",
    "        (\n",
    "            (\n",
    "                stimulus_pres[\"stimulus_name\"] == \"drifting_gratings\"\n",
    "            )  # brain_observatory_1.1\n",
    "            | (\n",
    "                stimulus_pres[\"stimulus_name\"] == \"drifting_gratings_75_repeats\"\n",
    "            )  # functional_connectivity\n",
    "        )\n",
    "        & (stimulus_pres[\"orientation\"] != \"null\")\n",
    "    ]\n",
    "\n",
    "    start_times = drifting_gratings[\"start_time\"].values\n",
    "    end_times = drifting_gratings[\"stop_time\"].values\n",
    "    orientations = drifting_gratings[\"orientation\"].values.astype(np.float32)\n",
    "    orientations = np.round(orientations / 45.0).astype(np.int64)\n",
    "    temp_freq_mapping = {1.0: 0, 2.0: 1, 4.0: 2, 8.0: 3, 15.0: 4}\n",
    "    temp_freq = np.array(\n",
    "        [\n",
    "            temp_freq_mapping[freq]\n",
    "            for freq in drifting_gratings[\"temporal_frequency\"].values\n",
    "        ]\n",
    "    )\n",
    "    drifting_gratings_dict = {\n",
    "        \"start\": start_times,\n",
    "        \"end\": end_times,\n",
    "        \"orientation\": orientations,  # (N,)\n",
    "        \"temp_freq\": temp_freq,  # (N,)\n",
    "        # NOTE for now, we will center all timestamps assuming a context window of 1s\n",
    "        \"timestamps\": np.ones_like(start_times) * 0.5,\n",
    "    }\n",
    "    assert np.all(\n",
    "        drifting_gratings_dict[\"end\"] - drifting_gratings_dict[\"start\"] > 1\n",
    "    ), \"All trials must have a duration greater than 1.\"\n",
    "    return drifting_gratings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stim_trial_splits(stim_dict, split_ratios=[0.7, 0.1, 0.2]):\n",
    "    if stim_dict is None or len(stim_dict[\"timestamps\"]) == 0:\n",
    "        return {\"train\": None, \"valid\": None, \"test\": None}\n",
    "    import math\n",
    "\n",
    "    train_boundary = math.floor(len(stim_dict[\"timestamps\"]) * split_ratios[0])\n",
    "    valid_boundary = math.floor(len(stim_dict[\"timestamps\"]) * (split_ratios[0] + split_ratios[1]))\n",
    "    test_boundary = math.floor(len(stim_dict[\"timestamps\"]) * sum(split_ratios))\n",
    "    \n",
    "    stim_trials = np.vstack([stim_dict[\"start\"], stim_dict[\"end\"]]).T\n",
    "    train_trials = stim_trials[:train_boundary - 1] \n",
    "    valid_trials = stim_trials[train_boundary: valid_boundary - 1] \n",
    "    test_trials = stim_trials[valid_boundary: test_boundary - 1] \n",
    "    \n",
    "    return {\"train\": train_trials, \"valid\": valid_trials, \"test\": test_trials}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.42694, 9195.1129)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_behavior_region(running_speed_dict, pupil_dict=None, gaze_dict=None):\n",
    "    # extract session start and end times\n",
    "    session_start = min(\n",
    "        running_speed_dict[\"timestamps\"].min() if running_speed_dict is not None else np.inf,\n",
    "        pupil_dict[\"timestamps\"].min() if pupil_dict is not None else np.inf,\n",
    "        gaze_dict[\"timestamps\"].min() if gaze_dict is not None else np.inf,\n",
    "    )\n",
    "    session_end = max(\n",
    "        running_speed_dict[\"timestamps\"].max() if running_speed_dict is not None else 0,\n",
    "        pupil_dict[\"timestamps\"].max() if pupil_dict is not None else 0,\n",
    "        gaze_dict[\"timestamps\"].max() if gaze_dict is not None else 0,\n",
    "    )\n",
    "    assert (\n",
    "        session_start < session_end\n",
    "    ), \"Atleast one of running_speed, pupil or gaze data must be present.\"\n",
    "    return session_start, session_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This ecephys session '715093703' has no eye tracking data. (NWB error: \"'raw_gaze_mapping' not found in processing of NWBFile 'root'.\")\n",
      "This ecephys session '715093703' has no eye tracking data. (NWB error: \"'eye_tracking' not found in processing of NWBFile 'root'.\")\n"
     ]
    }
   ],
   "source": [
    "# extract behavior and stimuli data\n",
    "# using dedicated extract_* helpers into a dictionary\n",
    "supervision_dict = {\n",
    "    \"running_speed\": extract_running_speed(session_data),\n",
    "    \"gaze\": extract_gaze(session_data),\n",
    "    \"pupil\": extract_pupil(session_data),\n",
    "    \"drifting_gratings\": extract_drifting_gratings(stimulus_presentations),\n",
    "    \"static_gratings\": extract_static_gratings(stimulus_presentations),\n",
    "    \"gabors\": extract_gabors(stimulus_presentations),\n",
    "    \"natural_scenes\": extract_natural_scenes(stimulus_presentations),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each stimuli/behavior and combine them\n",
    "# using dedicated get_*_splits helpers into a dictionary\n",
    "stimuli_splits_by_key = {\n",
    "    \"drifting_gratings\": get_stim_trial_splits(\n",
    "        supervision_dict.get(\"drifting_gratings\", None)\n",
    "    ),\n",
    "    \"static_gratings\": get_stim_trial_splits(\n",
    "        supervision_dict.get(\"static_gratings\", None)\n",
    "    ),\n",
    "    \"gabors\": get_stim_trial_splits(supervision_dict.get(\"gabors\", None)),\n",
    "    \"natural_scenes\": get_stim_trial_splits(\n",
    "        supervision_dict.get(\"natural_scenes\", None)\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_start, behavior_end = get_behavior_region(\n",
    "    supervision_dict.get(\"running_speed\", None),\n",
    "    supervision_dict.get(\"pupil\", None),\n",
    "    supervision_dict.get(\"gaze\", None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n",
      "INFO:call_caching:Reading data from cache\n"
     ]
    }
   ],
   "source": [
    "spikes, units = extract_spikes(session_data, session_id)\n",
    "\n",
    "session_dict = {\"data\": {}, \"splits\": {}}\n",
    "\n",
    "session_dict[\"data\"] = {\n",
    "    \"spikes\": spikes,\n",
    "    \"units\": units,\n",
    "    **supervision_dict,\n",
    "}\n",
    "\n",
    "session_dict[\"splits\"] = {\n",
    "    \"stimuli_splits_by_key\": stimuli_splits_by_key,\n",
    "    \"behavior_start\": behavior_start,\n",
    "    \"behavior_end\": behavior_end,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved to disk session: 715093703\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{output_dir}/{session_id}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(session_dict, f)\n",
    "\n",
    "logging.info(f\"Saved to disk session: {session_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
